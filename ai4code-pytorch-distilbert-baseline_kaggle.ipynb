{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AI4Code Pytorch DistilBert Baseline\n\nI used a lot of code from Kaggle's starter notebook here: https://www.kaggle.com/code/ryanholbrook/getting-started-with-ai4code\n\nI replaced their model with a DistilBert model.","metadata":{"papermill":{"duration":0.031568,"end_time":"2022-05-12T10:15:13.890382","exception":false,"start_time":"2022-05-12T10:15:13.858814","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import sparse\nfrom tqdm import tqdm\n\npd.options.display.width = 180\npd.options.display.max_colwidth = 120\n\nBERT_PATH = \"../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased\"\ndata_dir = Path('../input/train_markdown_ranks')\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:52:34.097641Z","iopub.execute_input":"2022-07-08T10:52:34.098119Z","iopub.status.idle":"2022-07-08T10:52:34.160697Z","shell.execute_reply.started":"2022-07-08T10:52:34.097989Z","shell.execute_reply":"2022-07-08T10:52:34.159974Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"data_path = '../input/train-markdown-ranks/train_markdown_ranks.fth'\ndf = pd.read_feather(data_path)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:52:34.163629Z","iopub.execute_input":"2022-07-08T10:52:34.164072Z","iopub.status.idle":"2022-07-08T10:52:34.897492Z","shell.execute_reply.started":"2022-07-08T10:52:34.164033Z","shell.execute_reply":"2022-07-08T10:52:34.896815Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import pytorch_lightning as pl\nfrom pytorch_lightning import LightningModule, Trainer\n\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import DistilBertModel, DistilBertTokenizer\n\nfrom sklearn.model_selection import GroupShuffleSplit\n\nMAX_LEN = 128\nNVALID = 0.1\n\n\nclass MarkdownDataset(Dataset):\n    def __init__(self, df, max_len=MAX_LEN):\n        super().__init__()\n        self.df = df.reset_index(drop=True)\n        self.max_len = max_len\n        self.tokenizer = DistilBertTokenizer.from_pretrained(BERT_PATH, do_lower_case=True)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n\n        inputs = self.tokenizer.encode_plus(\n            row.source,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            padding=\"max_length\",\n            return_token_type_ids=True,\n            truncation=True\n        )\n        ids = torch.LongTensor(inputs['input_ids'])\n        mask = torch.LongTensor(inputs['attention_mask'])\n\n        return ids, mask, torch.FloatTensor([row.pct_rank])\n\n    def __len__(self):\n        return self.df.shape[0]\n    \n\nclass MarkdownDataModule(pl.LightningDataModule):\n    def __init__(\n            self, train_path: str = None, batch_size: int = 32,\n            train_dat=None, val_dat=None\n    ):\n        super().__init__()\n\n        self.train_path = train_path\n        self.batch_size = batch_size\n\n        self.train_dataset, self.val_dataset = train_dat, val_dat\n\n    def setup(self, stage=None):\n        if stage == 'fit' or stage is None:\n            self._prepare_dataset()\n\n        if stage == 'test' or stage is None:\n            pass\n\n    def train_dataloader(self):\n        return DataLoader(self.train_dataset,\n                          batch_size=self.batch_size, num_workers=1,\n                          pin_memory=True, shuffle=True)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_dataset,\n                          batch_size=self.batch_size, num_workers=1,\n                          pin_memory=True)\n\n    def _prepare_dataset(self):\n        if (self.train_dataset is not None) and (self.val_dataset is not None):\n            return \n        \n        df = pd.read_feather(self.train_path)\n\n        splitter = GroupShuffleSplit(n_splits=1, test_size=NVALID, random_state=0)\n        train_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n        train_df, val_df = df.loc[train_ind].reset_index(drop=True), df.loc[val_ind].reset_index(drop=True)\n\n        train_ds = MarkdownDataset(train_df, max_len=MAX_LEN)\n        val_ds = MarkdownDataset(val_df, max_len=MAX_LEN)\n\n        self.train_dataset, self.val_dataset = train_ds, val_ds","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:54:10.271001Z","iopub.execute_input":"2022-07-08T10:54:10.271268Z","iopub.status.idle":"2022-07-08T10:54:10.296362Z","shell.execute_reply.started":"2022-07-08T10:54:10.271231Z","shell.execute_reply":"2022-07-08T10:54:10.295533Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"import sys, os\nimport torch.nn.functional as F\nimport torch.nn as nn\nimport torch\n\nfrom tqdm import tqdm\n\n\ndef read_data(data):\n    return tuple(d for d in data[:-1]), data[-1]\n\n\ndef validate(model, val_loader):\n    model.eval()\n    \n    tbar = tqdm(val_loader, file=sys.stdout)\n    \n    preds = []\n    labels = []\n\n    with torch.no_grad():\n        for idx, data in enumerate(tbar):\n            inputs, target = read_data(data)\n\n            pred = model(inputs[0].cuda(), inputs[1].cuda())\n\n            preds.append(pred.detach().cpu().numpy().ravel())\n            labels.append(target.detach().cpu().numpy().ravel())\n    \n    return np.concatenate(labels), np.concatenate(preds)\n\n\nclass MarkdownModelPl(LightningModule):\n    def __init__(self):\n        super(MarkdownModelPl, self).__init__()\n        self.distill_bert = DistilBertModel.from_pretrained(BERT_PATH)\n        self.top = nn.Linear(768, 1)\n        \n        self.criterion = torch.nn.MSELoss()\n    \n    def forward(self, ids, mask):\n        x = self.distill_bert(ids, mask)[0]\n        x = self.top(x[:, 0, :])\n        return x\n\n    def training_step(self, batch, batch_idx):\n        inputs, target = self.__read_data(batch)\n        pred = self(inputs[0], inputs[1])\n\n        loss = self.criterion(pred, target)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(\n            filter(lambda p: p.requires_grad, self.parameters()),\n            lr=3e-4, betas=(0.9, 0.999), eps=1e-08)\n        return optimizer\n\n    @staticmethod\n    def __read_data(data):\n        return tuple(d for d in data[:-1]), data[-1]\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:54:10.364597Z","iopub.execute_input":"2022-07-08T10:54:10.365031Z","iopub.status.idle":"2022-07-08T10:54:10.387003Z","shell.execute_reply.started":"2022-07-08T10:54:10.364996Z","shell.execute_reply":"2022-07-08T10:54:10.386320Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"MDM = MarkdownDataModule(data_path)\nmodel = MarkdownModelPl()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:54:10.675394Z","iopub.execute_input":"2022-07-08T10:54:10.675637Z","iopub.status.idle":"2022-07-08T10:54:11.366895Z","shell.execute_reply.started":"2022-07-08T10:54:10.675608Z","shell.execute_reply":"2022-07-08T10:54:11.366172Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(gpus=1, max_epochs=1)\ntrainer.fit(model, MDM)","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:54:11.720127Z","iopub.execute_input":"2022-07-08T10:54:11.720452Z","iopub.status.idle":"2022-07-08T10:57:20.629181Z","shell.execute_reply.started":"2022-07-08T10:54:11.720420Z","shell.execute_reply":"2022-07-08T10:57:20.628272Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"test_path = '../input/train-markdown-ranks/test_dataset.fth'\ntest_df = pd.read_feather(test_path)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:57:23.336859Z","iopub.execute_input":"2022-07-08T10:57:23.337159Z","iopub.status.idle":"2022-07-08T10:57:23.363150Z","shell.execute_reply.started":"2022-07-08T10:57:23.337128Z","shell.execute_reply":"2022-07-08T10:57:23.362360Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_df[\"pct_rank\"] = 0\ntest_ds = MarkdownDataset(\n    test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), max_len=MAX_LEN\n)\ntest_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=1,\n                          pin_memory=False, drop_last=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:57:24.214828Z","iopub.execute_input":"2022-07-08T10:57:24.215084Z","iopub.status.idle":"2022-07-08T10:57:24.262113Z","shell.execute_reply.started":"2022-07-08T10:57:24.215055Z","shell.execute_reply":"2022-07-08T10:57:24.261404Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"_, y_test = validate(model, test_loader)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:57:25.174491Z","iopub.execute_input":"2022-07-08T10:57:25.174770Z","iopub.status.idle":"2022-07-08T10:57:25.471011Z","shell.execute_reply.started":"2022-07-08T10:57:25.174736Z","shell.execute_reply":"2022-07-08T10:57:25.470227Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\nsub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\nsub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\nsub_df.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:57:26.262471Z","iopub.execute_input":"2022-07-08T10:57:26.262756Z","iopub.status.idle":"2022-07-08T10:57:26.284638Z","shell.execute_reply.started":"2022-07-08T10:57:26.262705Z","shell.execute_reply":"2022-07-08T10:57:26.283915Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\", index=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-07-08T10:57:27.894311Z","iopub.execute_input":"2022-07-08T10:57:27.895014Z","iopub.status.idle":"2022-07-08T10:57:27.903984Z","shell.execute_reply.started":"2022-07-08T10:57:27.894974Z","shell.execute_reply":"2022-07-08T10:57:27.903272Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}