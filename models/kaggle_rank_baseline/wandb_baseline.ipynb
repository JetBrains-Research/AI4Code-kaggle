{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from data_managment.samplers import MDSampler\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "class MarkdownDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, train_path: str = None, test_path: str =None, batch_size: int = 32, resample = False,\n",
    "                 train_dat=None, val_dat=None, test_dat=None, model = \"distilbert-base-uncased\"):\n",
    "        super().__init__()\n",
    "\n",
    "        self.test_path = test_path\n",
    "        self.train_path = train_path\n",
    "        self.resample = resample\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_size = 0.1\n",
    "        self.padding = 128\n",
    "\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained(model, do_lower_case=True)\n",
    "\n",
    "        self.train_dataset, self.val_dataset, test_dataset = train_dat, val_dat, test_dat\n",
    "\n",
    "    def _read_train_dataset(self):\n",
    "\n",
    "        df = pd.read_feather(self.train_path)\n",
    "\n",
    "        if self.resample:\n",
    "            sampler = MDSampler(df)\n",
    "            df = sampler.sample_ranks(save = False)\n",
    "\n",
    "        df = df.rename(columns = {'pct_rank':'score'})\n",
    "        train_df, val_df = self._split_if_ancestors(df)\n",
    "\n",
    "        train_dataset = Dataset.from_pandas(train_df)\n",
    "        validation_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "        return train_dataset, validation_dataset\n",
    "\n",
    "    def _read_test_dataset(self):\n",
    "        df = pd.read_feather(self.test_path)\n",
    "\n",
    "        sampler = MDSampler(df)\n",
    "        df = sampler.sample_ranks(save = False)\n",
    "        df = df.rename(columns = {'pct_rank':'score'})\n",
    "        test_dataset = Dataset.from_pandas(df)\n",
    "        return test_dataset\n",
    "\n",
    "\n",
    "    def _preprocess_dataset(self, dataset):\n",
    "\n",
    "\n",
    "        def process_batch(batch):\n",
    "            tokenized = self.tokenizer(\n",
    "                batch['source'],\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=self.padding\n",
    "            )\n",
    "            return tokenized\n",
    "\n",
    "        dataset = dataset.map(\n",
    "            lambda batch: process_batch(batch),\n",
    "            batched=True, batch_size=self.batch_size,\n",
    "        )\n",
    "\n",
    "        dataset.set_format('pt', ['input_ids', 'attention_mask', 'score'])\n",
    "\n",
    "        return dataset\n",
    "\n",
    "    def _split_if_ancestors(self, df):\n",
    "\n",
    "        splitter = GroupShuffleSplit(n_splits=1, test_size=self.validation_size, random_state=0)\n",
    "        train_ind, val_ind = next(splitter.split(df, groups=df[\"ancestor_id\"]))\n",
    "        train_df, val_df = df.loc[train_ind].reset_index(drop=True), df.loc[val_ind].reset_index(drop=True)\n",
    "\n",
    "        return train_df, val_df\n",
    "\n",
    "    def prepare_data(self):\n",
    "\n",
    "        if (self.train_dataset is not None) and (self.val_dataset is not None) and (self.test_dataset is not None):\n",
    "            return\n",
    "        train, val = self._read_train_dataset()\n",
    "        test = self._read_test_dataset()\n",
    "        print('preparing train data')\n",
    "        self.train_dataset = self._preprocess_dataset(train)\n",
    "        print('preparing validation data')\n",
    "        self.val_dataset = self._preprocess_dataset(val)\n",
    "        print('preparing test data')\n",
    "        self.test_dataset = self._preprocess_dataset(test)\n",
    "\n",
    "\n",
    "    # def setup(self, stage=None):\n",
    "    #     if stage == 'fit' or stage is None:\n",
    "    #         pass\n",
    "    #\n",
    "    #     if stage == 'test' or stage is None:\n",
    "    #         pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset,\n",
    "                          batch_size=self.batch_size, num_workers=4,\n",
    "                          pin_memory=True, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset,\n",
    "                          batch_size=self.batch_size, num_workers=4,\n",
    "                          pin_memory=True)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "train = '../../data/train_dataset.fth'\n",
    "test = '../../data/test_dataset.fth'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "MDM = MarkdownDataModule(train_path=train, test_dat=test, resample=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "MDM.prepare_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from rank_model import MarkdownModelPl\n",
    "\n",
    "MDM = MarkdownDataModule('data/ranks.fth')\n",
    "model = MarkdownModelPl()\n",
    "wandb_logger = WandbLogger(project=\"JupyterKaggleBaseline\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    gpus = 1,\n",
    "    max_epochs=20,\n",
    "    logger=wandb_logger,\n",
    "    enable_progress_bar=False,\n",
    "    log_every_n_steps=20,\n",
    "    accumulate_grad_batches=4,\n",
    ")\n",
    "trainer.fit(model, MDM)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creating submission"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_path: str = '../input/train-markdown-ranks/test_dataset.fth'\n",
    "test_df = pd.read_feather(test_path)\n",
    "test_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df[\"pct_rank\"] = 0\n",
    "test_ds = MarkdownDataset(\n",
    "    test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), max_len=MAX_LEN\n",
    ")\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=1,\n",
    "                          pin_memory=False, drop_last=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "_, y_test = validate(model, test_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\n",
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission.csv\", index=False)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "False"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "False | False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}