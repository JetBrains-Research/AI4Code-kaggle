optimizer_config:
    lr: 1e-5
    eps: 1e-08
    weight_decay: 1e-02
    betas: [0.9, 0.99]


model: microsoft/graphcodebert-base
batch_size: 32

training_steps: 5000
val_check_interval: 500
accumulate_grad_batches: 1
